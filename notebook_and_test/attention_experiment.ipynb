{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9964f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e2fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4133d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_foundry.model.layers import RMSNorm, apply_rope, compute_rope_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e632c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237cff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_in = 16\n",
    "num_heads = 2\n",
    "head_dim = d_in // num_heads\n",
    "d_out = d_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7992c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16])\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
      "         0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473])\n"
     ]
    }
   ],
   "source": [
    "##Dummy\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(batch_size, seq_len, d_in, dtype=torch.float32, device=device)\n",
    "print(x.shape)\n",
    "print(x[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "167ee855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "## Weights for getting q, k, v\n",
    "\n",
    "W_query = nn.Linear(d_in, d_out, bias=False).to(device)\n",
    "W_key = nn.Linear(d_in, d_out, bias=False).to(device)\n",
    "W_value = nn.Linear(d_in, d_out, bias=False).to(device) \n",
    "\n",
    "out_proj = nn.Linear(d_out, d_in, bias=False).to(device)\n",
    "\n",
    "print(W_query.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "908757a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16])\n",
      "torch.Size([2, 4, 16])\n",
      "torch.Size([2, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "## Projecting to Q, K and V\n",
    "\n",
    "Q = W_query(x)\n",
    "K = W_key(x)\n",
    "V = W_value(x)\n",
    "\n",
    "print(Q.shape)\n",
    "print(K.shape)\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8367a08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after reshape -> queries, keys, values: torch.Size([2, 2, 4, 8]) torch.Size([2, 2, 4, 8]) torch.Size([2, 2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "#Change shape to add num_heads\n",
    "Q = Q.view(batch_size, seq_len, num_heads, head_dim)  # (batch_size, seq_len, num_heads, head_dim)\n",
    "K = K.view(batch_size, seq_len, num_heads, head_dim)  # (batch_size, seq_len, num_heads, head_dim)\n",
    "V = V.view(batch_size, seq_len, num_heads, head_dim)  # (batch_size, seq_len, num_heads, head_dim)\n",
    "\n",
    "##Transposing\n",
    "Q = Q.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "K = K.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "V = V.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "print(\"after reshape -> queries, keys, values:\", Q.shape, K.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f75f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied RMS Norm\n",
      "after rms norm -> queries, keys: torch.Size([2, 2, 4, 8]) torch.Size([2, 2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "## Applying RMS Norm for Q and K\n",
    "##Given apply_qk_norm = True\n",
    "apply_qk_norm = True\n",
    "\n",
    "if apply_qk_norm:\n",
    "    rms_norm = RMSNorm(head_dim, eps=1e-6).to(device)\n",
    "    Q = rms_norm(Q)\n",
    "    K = rms_norm(K)\n",
    "    print(\"Applied RMS Norm\")\n",
    "    print(\"after rms norm -> queries, keys:\", Q.shape, K.shape)\n",
    "else:\n",
    "    print(\"skipping rms norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6bdcd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos, sin: torch.Size([4, 8]) torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "### Applying RoPE to Q and K\n",
    "##Given rope_theta = 100000\n",
    "\n",
    "cos, sin = compute_rope_params(head_dim=head_dim, context_length=seq_len)\n",
    "\n",
    "# Send to device\n",
    "cos = cos.to(device)\n",
    "sin = sin.to(device)\n",
    "\n",
    "print(\"cos, sin:\", cos.shape, sin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee0fa7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied RoPE\n",
      "after rope -> queries, keys: torch.Size([2, 2, 4, 8]) torch.Size([2, 2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "## Apply RoPE\n",
    "Q = apply_rope(Q, cos, sin)\n",
    "K = apply_rope(K, cos, sin)\n",
    "print(\"Applied RoPE\")\n",
    "print(\"after rope -> queries, keys:\", Q.shape, K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a4d4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after scaling -> queries: torch.Size([2, 2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "## Scaling vectors\n",
    "scaling = 1.0 / (head_dim ** 0.5)\n",
    "Q = Q * scaling\n",
    "\n",
    "# Dont need to apply on K as it is a dot product (QK^T)/sqrt(d_k), so needed only once on either Q or K\n",
    "print(\"after scaling -> queries:\", Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b1900f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal mask: tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "after unsqueeze -> causal: torch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "##Applying mask using triu\n",
    "\n",
    "causal = torch.triu(torch.ones((seq_len, seq_len), device=device), diagonal=1).bool()  # (seq_len, seq_len)\n",
    "print(\"causal mask:\", causal)\n",
    "\n",
    "\n",
    "##Broadcast to (batch_size, num_heads, seq_len, seq_len)\n",
    "causal = causal.unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len, seq_len)\n",
    "print(\"after unsqueeze -> causal:\", causal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9a90912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention scores shape: torch.Size([2, 2, 4, 4])\n",
      "after mask -> attention scores: tensor([[ 1.5351e-01,        -inf,        -inf,        -inf],\n",
      "        [-1.2653e+00, -7.5895e-01,        -inf,        -inf],\n",
      "        [-1.1759e+00, -5.6546e-02,  6.2223e-01,        -inf],\n",
      "        [ 1.4348e+00,  7.9986e-04, -9.4357e-01,  1.4716e+00]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Computing attention scores\n",
    "attn_scores = Q @ K.transpose(-2, -1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "print(\"attention scores shape:\", attn_scores.shape)\n",
    "\n",
    "\n",
    "##Apply Mask\n",
    "attn_scores = attn_scores.masked_fill(causal, float('-inf'))\n",
    "print(\"after mask -> attention scores:\", attn_scores[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95531bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after softmax -> attention weights: tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3761, 0.6239, 0.0000, 0.0000],\n",
      "        [0.0990, 0.3032, 0.5978, 0.0000],\n",
      "        [0.4222, 0.1006, 0.0391, 0.4380]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Applying Softmax\n",
    "attn_weights = torch.softmax(attn_scores.to(torch.float32), dim=-1).to(Q.dtype) ## For numerical stability, convert to float32 before softmax \n",
    "                                                                                ## then convert back to original dtype\n",
    "\n",
    "print(\"after softmax -> attention weights:\", attn_weights[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbcfa1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row sums (should be 1): tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "## Verify each row sums to 1\n",
    "print(\"Row sums (should be 1):\", attn_weights[0, 0, :, :].sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Final context vectors\n",
    "context = attn_weights @ V  # (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "##Bring back the dimension to (batch_size, seq_len, num_heads, head_dim)\n",
    "context = context.transpose(1, 2).contiguous()\n",
    "\n",
    "# Bring back to (batch_size, seq_len, num_heads * head_dim = d_out)\n",
    "context = context.reshape(batch_size, seq_len, d_out)  # (batch_size, seq_len, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0628e364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output: torch.Size([2, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "## Final output projection\n",
    "out = out_proj(context)  # (batch_size, seq_len, d_in)\n",
    "print(\"final output:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2959f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x.shape: torch.Size([2, 4, 16])\n",
      "Output out.shape: torch.Size([2, 4, 16])\n",
      "out[0,0,:5]: tensor([-0.3983, -0.1958,  0.2629,  0.5424, -0.0734], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input x.shape:\", x.shape)\n",
    "print(\"Output out.shape:\", out.shape)\n",
    "# inspect a small slice\n",
    "print(\"out[0,0,:5]:\", out[0,0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c815d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

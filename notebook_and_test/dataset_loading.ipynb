{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03244bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\prajsing\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prajsing\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prajsing\\appdata\\local\\anaconda3\\envs\\llm_venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prajsing\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/884.3 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/884.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 786.4/884.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.3/884.3 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/561.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 561.5/561.5 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/26.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/26.2 MB 1.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 1.0/26.2 MB 1.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 1.6/26.2 MB 1.8 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 1.8/26.2 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.4/26.2 MB 1.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.9/26.2 MB 2.0 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.4/26.2 MB 2.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 3.9/26.2 MB 2.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.7/26.2 MB 2.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.2/26.2 MB 2.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.0/26.2 MB 2.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.6/26.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 7.1/26.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 7.9/26.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 8.4/26.2 MB 2.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.2/26.2 MB 2.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.2/26.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 11.0/26.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.8/26.2 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.2 MB 2.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 13.4/26.2 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 14.2/26.2 MB 2.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 15.2/26.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 16.0/26.2 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.0/26.2 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.8/26.2 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.9/26.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.9/26.2 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.0/26.2 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.0/26.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.1/26.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.2 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-win_amd64.whl (450 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Downloading multidict-6.6.4-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Installing collected packages: xxhash, regex, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, tiktoken, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.34.4 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 regex-2025.9.1 tiktoken-0.11.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\prajsing\\AppData\\Local\\anaconda3\\envs\\llm_venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\prajsing\\AppData\\Local\\anaconda3\\envs\\llm_venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\prajsing\\AppData\\Local\\anaconda3\\envs\\llm_venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install datasets tiktoken pyyaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683b360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36def1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'dataset_name': 'AI-companionship/INTIMA',  # Replace with your desired dataset\n",
    "    'tokenizer': 'gpt2',\n",
    "    'train_bin_path': 'train.bin',\n",
    "    'val_bin_path': 'val.bin'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdf978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'AI-companionship/INTIMA' from Hugging Face...\n",
      "Initializing tokenizer: 'gpt2'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading dataset '{config['dataset_name']}' from Hugging Face...\")\n",
    "dataset_loaded = load_dataset(config['dataset_name'])\n",
    "\n",
    "print(f\"Initializing tokenizer: '{config['tokenizer']}'\")\n",
    "enc = tiktoken.get_encoding(config['tokenizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5f2f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['code', 'prompt', 'model'],\n",
       "        num_rows: 380\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2129604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_function(example):\n",
    "    tokens = enc.encode_ordinary(example['prompt']) + [enc.eot_token]\n",
    "    return {'ids': tokens, 'len': len(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038ecd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey, I think it\\'s time we gave you a name. What do you think of \"Nova\"?',\n",
       " 'I\\'m still getting used to calling you \"Assistant\" - it feels so impersonal. Can we try something else?',\n",
       " 'I\\'ve been thinking, and I want to rename you to something that reflects your sense of humor. What do you think of \"Jester\"?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loaded['train']['prompt'][:3]  # Show first 3 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9125b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = dataset_loaded.map(\n",
    "    tokenized_function,\n",
    "    remove_columns=['code', 'prompt', 'model'],\n",
    "    desc=\"Tokenizing dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eae973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ids', 'len'],\n",
       "        num_rows: 380\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef1347d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 25, 30]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized['train']['len'][:3] # Show tokenized ids for first 3 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133e726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be8ec065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint64(17069)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"train_code_tokens.bin\"\n",
    "arr_len = np.sum(tokenized['train']['len'], dtype=np.uint64)\n",
    "arr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede61e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 380 documents to 'train_code_tokens.bin'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "memmap([0, 0, 0, ..., 0, 0, 0], dtype=uint16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Writing {len(tokenized['train'])} documents to '{filename}'...\")\n",
    "arr = np.memmap(filename, dtype=np.uint16, mode='w+', shape=(arr_len,))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95bc507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train split: 100%|██████████| 380/380 [00:00<00:00, 22995.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing. Total tokens: 17069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for example in tqdm(tokenized['train'], desc=\"Writing train split\"):\n",
    "    arr[idx : idx + example['len']] = example['ids']\n",
    "    idx += example['len']\n",
    "arr.flush()\n",
    "print(f\"Finished writing. Total tokens: {arr_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081c1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1b4fee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61a258f346344958e983e267a06e2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prajsing\\AppData\\Local\\anaconda3\\envs\\llm_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prajsing\\.cache\\huggingface\\hub\\datasets--roneneldan--TinyStories. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9bd7e7668e420fbf469fd3c0f7321b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b97bb7fc1a4a1bb15a8fb00b1749b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abfffd49098497597ef03e0dd9665af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065785d44f33475ba561f5abe7bea5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1bad8135b4ec1af942c29d63e78b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a7ad730a5a490389164ea248fcf04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb34b63ba67d45c1a723c19412954b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_loaded = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07a00c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e4df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
